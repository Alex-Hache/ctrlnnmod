{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bon alors c'est quoi c't histoire de package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ctrl_nmod* Ouais le nom est pourri j'en trouverai un mieux plus tard\n",
    "\n",
    "C'est basé sur un peu la même architecture que PyTorch parce que c'est les mêmes besoins.\n",
    "\n",
    "Ce qui vous intéresse se trouve dans deux endroits : \n",
    "* ctrl_nmod/models/ssmodels/grnssm.py presque le modèle d'état le plus général qu'on peut concevoir \n",
    "* ctrl_nmod/utils/data.py et les classes **Experiments** et **ExperimentsDataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installation**\n",
    "\n",
    "Normalement si j'ai pas tout cassé\n",
    "\n",
    "``` pip install -e . ```\n",
    "\n",
    "devrait faire le job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiments***\n",
    "\n",
    "L'idée étant d'avoir une structure de données compatible avec un jeu de données composés de plusieurs trajectoires différentes (pas nécessairement de même longueur)\n",
    "\n",
    "Une **Experiment** est composé de (u,y) et éventuellement x si on a accès à l'état. \n",
    "Si on ne mesure pas l'état alors on crée un vecteur x du même longueur que u ou y.\n",
    "\n",
    "Dans ce cas on doit fournir la taille **nx** du vecteur d'état.\n",
    "\n",
    "On a ensuite le choix de rendre ce nouveau vecteur **trainable** ou pas c'est à dire de l'inclure dans le problème d'optimisation.\n",
    "\n",
    "On piochera dans cette expérience une séquence de **seq_len** de quadruplets (u, y, x, x0).\n",
    "\n",
    "La structure se débrouille pour ne pas prendre les **seq_len** derniers éléments de l'expérience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiments.png\" alt=\"Exemple experiments\" style=\"width:50%; height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ExperimentsDataset**\n",
    "\n",
    "C'est une classe qui implémente une liste d'*Experiments* et qui gère les indices avec la mise en batch.\n",
    "\n",
    "On peut donc ajouter une expérience au dataset avec la méthode append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctrl_nmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExperimentsDataset, Experiment\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpendulum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_pendulum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pendulum\n\u001b[1;32m      5\u001b[0m u_train, y_train, u_test, y_test, ts \u001b[38;5;241m=\u001b[39m load_pendulum([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_train_francois.mat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_test_francois.mat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Research/ctrlnnmod/ctrl_nmod/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# from . import matlab\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# from . import plot\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# from . import preprocessing\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n",
      "File \u001b[0;32m~/Research/ctrlnnmod/ctrl_nmod/models/__init__.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feedforward\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ssmodels\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedforward\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssmodels\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m ]\n",
      "File \u001b[0;32m~/Research/ctrlnnmod/ctrl_nmod/models/ssmodels/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhinf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m L2BoundedLinear\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NnLinear\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrenode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RENODE, DissipativeRENODE, ContractingRENODE\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REN, DissipativeREN, ContractingREN\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrnssm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLipGrnssm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContractingREN\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m ]\n",
      "File \u001b[0;32m~/Research/ctrlnnmod/ctrl_nmod/models/ssmodels/renode.py:17\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    This module implements Recurrent Equilibrium Networks in the acyclic case i.e. \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    with no implicit layers. It is a discrete model.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRENODE\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, nx: \u001b[38;5;28mint\u001b[39m, ny: \u001b[38;5;28mint\u001b[39m, nu: \u001b[38;5;28mint\u001b[39m, nq: \u001b[38;5;28mint\u001b[39m, sigma: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     19\u001b[0m                  device: torch\u001b[38;5;241m.\u001b[39mdevice, bias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m                  feedthrough: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28msuper\u001b[39m(RENODE, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/Research/ctrlnnmod/ctrl_nmod/models/ssmodels/renode.py:73\u001b[0m, in \u001b[0;36mRENODE\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLambda \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLambda_vec)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, u: torch\u001b[38;5;241m.\u001b[39mTensor, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    Forward pass of the network.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        tuple[torch.Tensor, torch.Tensor]: Next state and output.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from ctrl_nmod.utils.data import ExperimentsDataset, Experiment\n",
    "from data.pendulum.load_pendulum import load_pendulum\n",
    "\n",
    "\n",
    "u_train, y_train, u_test, y_test, ts = load_pendulum(['data_train_francois.mat', 'data_test_francois.mat'])\n",
    "u_train_yuqi, y_train_yuqi, u_test_yuqi, y_test_yuqi, ts = load_pendulum(['data_train_yuqi.mat', 'data_test_yuqi.mat'])\n",
    "\n",
    "# Length of sequences to consider\n",
    "seq_len = 20\n",
    "nx = 2\n",
    "\n",
    "train_set = ExperimentsDataset([Experiment(u_train, y_train, ts=ts, nx=nx, x_trainable=True)], seq_len)\n",
    "train_set.append(Experiment(u_train_yuqi, y_train_yuqi, ts=ts, nx=nx, x_trainable=True))\n",
    "test_set = ExperimentsDataset([Experiment(u_test, y_test, ts=ts, nx=nx)], seq_len)\n",
    "test_set.append(Experiment(u_test_yuqi, y_test_yuqi, ts=ts, nx=nx, x_trainable=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle d'état neuronal Grnssm**\n",
    "Pas le modèle le plus plus général qui soit puisque pas de terme direct mais on va dire que ça suffit.\n",
    "\n",
    "\n",
    "\n",
    "$\\begin{array}{ccc}\n",
    "    \\dot{x} &=& Ax + Bu + f(x,u) \\\\\n",
    "    y &=& Cx + h(x)\n",
    "    \\end{array}$\n",
    "\n",
    "\n",
    "où $f,h$ sont des MLP.\n",
    "\n",
    "Si votre système est proche du linéaire : ssest (la fonction matlab) renvoie un fit au-dessus 65% à la louche.\n",
    "\n",
    "Alors la partie linéaire est utile et vous pouvez l'initialiser avec ce qui sort de Matlab.\n",
    "\n",
    "Sinon le biais introduit par le linéaire risque de desservir l'apprentissage.\n",
    "\n",
    "Si votre fit linéaire est grand ~ 80% alors elle peut être gelée (on n'entraîne pas les poids). \n",
    "\n",
    "Vous gérez la partie linéaire en la gelant à 0 avec la méthode init_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ctrl_nmod.models.ssmodels.grnssm import Grnssm\n",
    "\n",
    "nu, ny, nh = 2, 1, 8\n",
    "# actF = 'relu'\n",
    "model = Grnssm(nu, ny, nx, nh)\n",
    "# A0, B0, C0, D0 = findBLA(u_train, y_train, nx, float(1/fs[0]), model_type='continuous')\n",
    "A0 = -torch.eye(nx)\n",
    "B0 = torch.Tensor([[0, 1], [1, 0]])\n",
    "C0 = torch.Tensor([[1, 0]])\n",
    "\n",
    "model.init_weights_(A0, B0, C0, isLinTrainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural ODEs**\n",
    "\n",
    "C'est juste l'ajout d'un intégrateur différentiable sur le modèle d'état.\n",
    "\n",
    "Pour l'instant 2 solveurs sont implémentés Runge-Kutta 4 et 45 à pas fixe donc c'est ODE45 à pas fixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctrl_nmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RK4Simulator\n\u001b[0;32m----> 2\u001b[0m sim_model \u001b[38;5;241m=\u001b[39m RK4Simulator(\u001b[43mmodel\u001b[49m, ts\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor([ts]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from ctrl_nmod.integrators.integrators import RK4Simulator\n",
    "sim_model = RK4Simulator(model, ts=torch.Tensor([ts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque importante sur l'initalisation:**\n",
    "\n",
    "Il faut nécessairement que votre $A_0$ soit stable (s'il existe) sinon vous ne pourrez pas entraîner votre modèle.\n",
    "\n",
    "Il est aussi possible que vous ayez des problèmes de stabilité du schéma d'intégration : \n",
    "\n",
    "le modèle continu est stable mais diverge à cause de l'intégration.\n",
    "\n",
    "Ca arrive ! Une solution est notamment d'utiliser une stratégie d'initialisation des poids\n",
    "en fonction du schéma.\n",
    "\n",
    "C'est encore un truc à implémenter dans ma TODO :)\n",
    "\n",
    "Sinon les autres solutions sont :\n",
    "* diminuer le pas donc la période d'échantillonage des données\n",
    "* trouver une initialisation qui donne un truc pas trop mal : l'initialisation par le linéaire en général suffit\n",
    "* utiliser le paramètre $alpha$ dans le constructeur du Grnssm il impose une borne sur la partie réelle des valeurs propres de A.\n",
    "\n",
    "$ \\Re(\\lambda_i(A)) \\leq -\\alpha$\n",
    "\n",
    "Mais ça coûte une peu plus en calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Losses et régularizations**\n",
    "\n",
    "Plusieurs loss sont implémentées uniquement de la régression.\n",
    "\n",
    "Chaque loss peut accepter une liste de termes de régularisaition :\n",
    "\n",
    "$\\mathcal{L} = MSE + \\sum_{i=1}^{N_{reg}} \\lambda_i \\mathcal{R}_i$\n",
    "\n",
    "Les $\\lambda_i$ sont les pondérations des régularisations. Ils sont mis à jour si la loss stagne plus de patience_soft **epochs testées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ctrl_nmod.losses.losses import MSELoss, NMSELoss\n",
    "from ctrl_nmod.regularizations.regularizations import StateRegularization\n",
    "loss = MSELoss([StateRegularization(model, 0.01, 0.0, updatable=False, verbose=True)])\n",
    "val_loss = NMSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entraînement**\n",
    "\n",
    "La classe SSTrainer inclus une méthode fit_ qui fait l'entraînement du modèle.\n",
    "\n",
    "La seule particularité est qu'une époque est réalisée lorsque l'on a parcouru tout le jeu de données.\n",
    "\n",
    "Ce qui veut dire tout les points de toutes les expériences.\n",
    "\n",
    "On évalue aussi la performance sur le jeu de test en simulation sur tout le jeu de données ce qui prend du temps.\n",
    "Un conseil est donc de mettre test_freq à une valeur plus grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctrl_nmod.plot.plots import plot_yTrue_vs_error\n",
    "from scipy.io import savemat\n",
    "from ctrl_nmod.train.train import SSTrainer\n",
    "\n",
    "trainer = SSTrainer(sim_model, loss=loss, val_loss=val_loss)\n",
    "\n",
    "# Training options\n",
    "\n",
    "batch_size, lr, keep_best = 128, 1e-3, True\n",
    "epochs, optimizer = 100, 'adamw'\n",
    "\n",
    "scheduled = True\n",
    "step_sched = 0.1\n",
    "save_path = f'results/try_1/{str(trainer)}'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "best_model, res = trainer.fit_(train_set=train_set, test_set=test_set,\n",
    "                               batch_size=batch_size, lr=lr, keep_best=keep_best,\n",
    "                               save_path=save_path, epochs=epochs, opt=optimizer,\n",
    "                               scheduled=True)\n",
    "\n",
    "\n",
    "# Best model simulation on test set\n",
    "x_sim, y_sim = best_model.simulate(test_set.experiments[0].u, torch.zeros(nx))\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "plot_yTrue_vs_error(test_set.experiments[0].y, y_sim, save_path + 'test_exp_1_sim.png')\n",
    "\n",
    "\n",
    "savemat(save_path + '/results.mat', res)\n",
    "\n",
    "torch.save(best_model, save_path + '/model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctrlnmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
